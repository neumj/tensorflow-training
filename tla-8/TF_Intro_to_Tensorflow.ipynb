{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import expectexception\n",
    "\n",
    "from pylib.draw_graph import draw_graph\n",
    "from pylib.tensorboardcmd import tensorboard_cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- requirement: pylib/__init__.py -->\n",
    "<!-- requirement: pylib/draw_graph.py -->\n",
    "\n",
    "# Introduction to TensorFlow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As artificial intelligence has advanced, applications have needed to process larger and larger amounts of data.  A prime example of this is the field of neural networks.  These machine learning models are enormously flexible and powerful, but they require huge amounts of both time and data to train.  Building tools to accomplish this can be difficult.\n",
    "\n",
    "Google had been using neural networks internally for some time when they decided to develop a single framework flexible enough to be used for many different purposes.  That project became TensorFlow, and it was released as an open-source project in November, 2015.  Version 1.0 was released just over a year later, in February, 2017.\n",
    "\n",
    "This generality has made TensorFlow useful for a number of different applications.  At its heart, it is a general-purpose computation engine, optimized for large data.  With TensorFlow, you define your program in terms of a computation graph.  Then, the graph is executed by letting data, in the form of tensors, flow through it.  (And you thought the name was just chosen to sound good!)\n",
    "\n",
    "This course will introduce you to both the basics of TensorFlow and the basics of neural networks.  By focusing on the basics, we hope to convey a solid understanding of the theory and practice behind neural networks in TensorFlow.  For purposes of time, many of our example will be small and short, and therefore will not produce spectacular results.  Nonetheless, this should be enough to get you started on your own spectacular projects!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics Covered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Introduction to TensorFlow\n",
    "\n",
    "\n",
    "- Iterative Algorithms\n",
    "\n",
    "\n",
    "- Machine Learning\n",
    "\n",
    "\n",
    "- Basic Neural Networks\n",
    "\n",
    "\n",
    "- Deep Neural Networks\n",
    "- Variational Autoencoders\n",
    "\n",
    "\n",
    "- Convolutional Neural Networks\n",
    "\n",
    "\n",
    "- Adversarial Noise\n",
    "- DeepDream\n",
    "\n",
    "\n",
    "- Recurrent Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow: The Computation Graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow, computations are conceptualized as graphs.  These graphs are **directed** (the edges have a direction) and **acyclic** (there are no loops).  The nodes of the are **operations**, which may have zero or more inputs and zero or more outputs.  Hooking the output of one operation into the input of the next produces the computation graph.\n",
    "\n",
    "Let's start with a simple demonstration.  Before we get going, we need to import TensorFlow.  The module name is `tensorflow`, but the usual convention is to import it as `tf`.  This avoids the namespace pollution that comes with an `import *`, but saves a lot of keystrokes over time.  We'll also import `numpy`, a Python library for numerical computation, as `np`, for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a basic computation, let's implement this pure-Python calculation in TensorFlow:\n",
    "```python\n",
    "x = 2\n",
    "y = 3\n",
    "sum_ = x + y\n",
    "```\n",
    "It should come as no surprise that addition is an operation.  In fact, it's implemented in the `tf.add()` function.  If we were to draw a graph of just the addition function, it would look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.36.0 (20140111.2315)\n",
       " -->\n",
       "<!-- Title: g Pages: 1 -->\n",
       "<svg width=\"264pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 264.00 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>g</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-94 260,-94 260,4 -4,4\"/>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\"><title>x</title>\n",
       "</g>\n",
       "<!-- tf.add -->\n",
       "<g id=\"node4\" class=\"node\"><title>tf.add</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"128\" cy=\"-45\" rx=\"37.8943\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"128\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">tf.add</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;tf.add -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>x&#45;&gt;tf.add</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.0111,-64.9061C63.4754,-62.3249 74.4311,-59.337 84.9305,-56.4735\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"86.0667,-59.7915 94.7934,-53.7836 84.2248,-53.0382 86.0667,-59.7915\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node2\" class=\"node\"><title>y</title>\n",
       "</g>\n",
       "<!-- y&#45;&gt;tf.add -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>y&#45;&gt;tf.add</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.0111,-25.0939C63.4754,-27.6751 74.4311,-30.663 84.9305,-33.5265\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.2248,-36.9618 94.7934,-36.2164 86.0667,-30.2085 84.2248,-36.9618\"/>\n",
       "</g>\n",
       "<!-- z -->\n",
       "<g id=\"node3\" class=\"node\"><title>z</title>\n",
       "</g>\n",
       "<!-- tf.add&#45;&gt;z -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>tf.add&#45;&gt;z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M165.864,-45C174.291,-45 183.241,-45 191.646,-45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"191.92,-48.5001 201.92,-45 191.92,-41.5001 191.92,-48.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fa00eed3898>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_graph(\"add-op\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The add operation takes two inputs and returns a single output.  Where do these inputs come from?  Other operations.  In this case, we'll use the `tf.constant()` operation.  This takes no input and produces a single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.36.0 (20140111.2315)\n",
       " -->\n",
       "<!-- Title: g Pages: 1 -->\n",
       "<svg width=\"220pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 220.00 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>g</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-40 216,-40 216,4 -4,4\"/>\n",
       "<!-- z -->\n",
       "<g id=\"node1\" class=\"node\"><title>z</title>\n",
       "</g>\n",
       "<!-- tf.constant -->\n",
       "<g id=\"node2\" class=\"node\"><title>tf.constant</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"61\" cy=\"-18\" rx=\"61.1893\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"61\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">tf.constant</text>\n",
       "</g>\n",
       "<!-- tf.constant&#45;&gt;z -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>tf.constant&#45;&gt;z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122.285,-18C130.967,-18 139.669,-18 147.686,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"147.772,-21.5001 157.772,-18 147.772,-14.5001 147.772,-21.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fa00eed3a90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_graph(\"const-op\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make a constant for each of `x` and `y` and connect these into the inputs of the add operation.  Constants can be made as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(2, name=\"input_x\")\n",
    "y = tf.constant(3, name=\"input_y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tf.constant()` function takes a single required argument, the value of the constant in question.  The `name` keyword is optional.  It helps to identify operations when examining the graph, so naming key operations will certainly save you time later.\n",
    "\n",
    "`x` and `y` are the output of operations, so they are tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_x:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll discuss what exactly a tensor is later on.  For now, it's enough to remember that all values are tensors, so all input and output to operations should be tensors.\n",
    "\n",
    "Now let's hook them up to calculate `x + y`.  The resulting graph should look like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.36.0 (20140111.2315)\n",
       " -->\n",
       "<!-- Title: g Pages: 1 -->\n",
       "<svg width=\"284pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 284.00 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>g</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-94 280,-94 280,4 -4,4\"/>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\"><title>x</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-72\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n",
       "</g>\n",
       "<!-- add -->\n",
       "<g id=\"node2\" class=\"node\"><title>add</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"120\" cy=\"-45\" rx=\"27.8951\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"120\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">add</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;add -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>x&#45;&gt;add</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M51.9092,-64.9061C61.9079,-61.9394 73.7176,-58.4354 84.6199,-55.2007\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"85.7078,-58.5288 94.2991,-52.3288 83.7166,-51.818 85.7078,-58.5288\"/>\n",
       "</g>\n",
       "<!-- sum_ -->\n",
       "<g id=\"node4\" class=\"node\"><title>sum_</title>\n",
       "</g>\n",
       "<!-- add&#45;&gt;sum_ -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>add&#45;&gt;sum_</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M148.245,-45C166.74,-45 191.407,-45 211.584,-45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"211.67,-48.5001 221.67,-45 211.67,-41.5001 211.67,-48.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"185\" y=\"-48.8\" font-family=\"Times,serif\" font-size=\"14.00\">sum_</text>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node3\" class=\"node\"><title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "</g>\n",
       "<!-- y&#45;&gt;add -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>y&#45;&gt;add</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M51.9092,-25.0939C61.9079,-28.0606 73.7176,-31.5646 84.6199,-34.7993\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.7166,-38.182 94.2991,-37.6712 85.7078,-31.4712 83.7166,-38.182\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fa00eed37b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_graph(\"simple-graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_ = tf.add(x, y, name=\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tf.add()` operation also takes an optional name.  The result is another tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sum:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what is the value of this tensor?  It doesn't have one, at least not yet.  TensorFlow takes a **lazy evaluation** model.  Values are not calculated until they are actually needed.  When we set `sum_` to be the output tensor of the add operation, that information was recorded into the computation graph, but nothing was calculated.  (The same thing also holds for `x` and `y`.)\n",
    "\n",
    "To find the value of `sum_`, we need to TensorFlow that this value should be computed.  We do that with the `Session.run()` function.  (We'll discuss sessions shortly.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(sum_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we ran the `sum_` tensor, TensorFlow could look at the computation graph and figure out that this was the output of the add operation.  Therefore, it needs to compute the inputs to this operation, namely the outputs of our two constant operations.  These tensors are fed into the add operation, and the output is fed back into Python for our use.  Graphically, something like this happened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.36.0 (20140111.2315)\n",
       " -->\n",
       "<!-- Title: g Pages: 1 -->\n",
       "<svg width=\"256pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 256.00 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>g</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-94 252,-94 252,4 -4,4\"/>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\"><title>x</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-72\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n",
       "</g>\n",
       "<!-- add -->\n",
       "<g id=\"node2\" class=\"node\"><title>add</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"128\" cy=\"-45\" rx=\"27.8951\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"128\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">add</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;add -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>x&#45;&gt;add</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.2181,-65.3951C64.2608,-62.1107 79.0324,-58.0821 92.2573,-54.4753\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"93.2714,-57.8266 101.998,-51.8187 91.4296,-51.0733 93.2714,-57.8266\"/>\n",
       "<text text-anchor=\"middle\" x=\"77\" y=\"-62.8\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node4\" class=\"node\"><title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"221\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">5</text>\n",
       "</g>\n",
       "<!-- add&#45;&gt;5 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>add&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.303,-45C164.976,-45 174.704,-45 183.898,-45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183.965,-48.5001 193.965,-45 183.965,-41.5001 183.965,-48.5001\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node3\" class=\"node\"><title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "</g>\n",
       "<!-- y&#45;&gt;add -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>y&#45;&gt;add</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.2181,-24.6049C64.2608,-27.8893 79.0324,-31.9179 92.2573,-35.5247\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"91.4296,-38.9267 101.998,-38.1813 93.2714,-32.1734 91.4296,-38.9267\"/>\n",
       "<text text-anchor=\"middle\" x=\"77\" y=\"-35.8\" font-family=\"Times,serif\" font-size=\"14.00\">3</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fa00eeef1d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_graph(\"simple-graph-run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors override a number of Python's operators become TensorFlow operators.  We could have also have written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum2 = x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, sum2 is a tensor, and its value is not calculated until we run the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(sum2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downside of this is that we could not give a name to this operation.  This doesn't affect the result of the computation, but it may make it harder to introspect the computation graph later.\n",
    "\n",
    "The standard mathematical operations are overwritten.  Be careful about `==`.  While it has been overridden, it only actually just checks identity.  To check if two tensors have the same values, you must use the `tf.equals()` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(7) == tf.constant(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.equal(tf.constant(7), tf.constant(7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Implementing a basic graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the following graph in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.36.0 (20140111.2315)\n",
       " -->\n",
       "<!-- Title: g Pages: 1 -->\n",
       "<svg width=\"380pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 380.00 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>g</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-94 376,-94 376,4 -4,4\"/>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\"><title>x</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-72\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n",
       "</g>\n",
       "<!-- add -->\n",
       "<g id=\"node2\" class=\"node\"><title>add</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"118\" cy=\"-64\" rx=\"27.8951\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"118\" y=\"-60.3\" font-family=\"Times,serif\" font-size=\"14.00\">add</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;add -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>x&#45;&gt;add</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.2216,-69.643C62.2413,-68.9221 71.2197,-68.1151 79.8226,-67.3418\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"80.394,-70.8046 90.0404,-66.4233 79.7672,-63.8327 80.394,-70.8046\"/>\n",
       "</g>\n",
       "<!-- multiply -->\n",
       "<g id=\"node4\" class=\"node\"><title>multiply</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"232\" cy=\"-41\" rx=\"49.2915\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"232\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">multiply</text>\n",
       "</g>\n",
       "<!-- add&#45;&gt;multiply -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>add&#45;&gt;multiply</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M144.977,-58.6655C154.973,-56.6128 166.781,-54.1879 178.393,-51.8031\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"179.406,-55.1682 188.498,-49.7281 177.998,-48.3113 179.406,-55.1682\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node3\" class=\"node\"><title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "</g>\n",
       "<!-- y&#45;&gt;add -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>y&#45;&gt;add</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M49.0918,-28.9014C60.3154,-34.7023 74.3162,-41.9387 86.6844,-48.3313\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"85.2606,-51.5352 95.7512,-53.0175 88.4747,-45.3167 85.2606,-51.5352\"/>\n",
       "</g>\n",
       "<!-- y&#45;&gt;multiply -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>y&#45;&gt;multiply</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M53.7101,-20.913C83.9387,-24.3379 135.004,-30.1236 174.588,-34.6085\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"174.312,-38.0995 184.642,-35.7477 175.1,-31.144 174.312,-38.0995\"/>\n",
       "</g>\n",
       "<!-- out -->\n",
       "<g id=\"node5\" class=\"node\"><title>out</title>\n",
       "</g>\n",
       "<!-- multiply&#45;&gt;out -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>multiply&#45;&gt;out</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M281.686,-41C290.451,-41 299.446,-41 307.779,-41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"307.913,-44.5001 317.913,-41 307.913,-37.5001 307.913,-44.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fa00eeefb38>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_graph(\"exercise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the output and check that you get the right answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow1=tf.multiply(x=sum_,y=y,name='multiply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(flow1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating calculations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of this seems like a lot of work to just add a couple of numbers together.  And it is, really&mdash;if you're just doing a calculation once, setting it up in TensorFlow is probably overkill.  Most of the time, though, we'll want to repeat calculations multiple times.  Then the work of setting up the computation graph will pay off.\n",
    "\n",
    "Part of this is the ability to compute only the necessary parts of a computation graph.  If you need to execute a partial result, you don't need to think about what leads into that computation.  TensorFlow will do exactly what needs to be computed and no more.\n",
    "\n",
    "TensorFlow also allows you to repeat a calculation with a different input value.  You can change the values of constants by feeding new values in through the `feed_dict` argument of the `run()` method.  For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(flow1, feed_dict={x: 10, y: 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the key in the `feed_dict` is the *tensor* itself, not its name.\n",
    "\n",
    "Many times we will do set up computation graphs with the intention of feeding in values each time.  To make sure we don't forget any keys in the `feed_dict`, we can use **placeholders**.  A placeholder is an operation much like a constant, but it needs to have a value fed in each time the graph is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp = tf.placeholder(dtype=tf.int32)\n",
    "sum_p = tf.add(xp, y)\n",
    "sess.run(sum_p, {xp: 5, y:10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't specify the feed values, we get an error.  (Note that the error occurs during the execution, and therefore comes from another process.  The result is that the traceback gets very hard to read.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n",
      "\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n",
      "\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n",
      "\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n",
      "\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_1' with dtype int32\n",
      "\t [[Node: Placeholder_1 = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-32-1538af8f3430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 2\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n",
      "\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n",
      "\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n",
      "\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n",
      "\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n",
      "\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n",
      "\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n",
      "\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n",
      "\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_1' with dtype int32\n",
      "\t [[Node: Placeholder_1 = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
      "\n",
      "Caused by op 'Placeholder_1', defined at:\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/asyncio/base_events.py\", line 1426, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/asyncio/events.py\", line 127, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-31-5fac3b6c2acc>\", line 1, in <module>\n",
      "    xp = tf.placeholder(dtype=tf.int32)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1735, in placeholder\n",
      "    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4925, in placeholder\n",
      "    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_1' with dtype int32\n",
      "\t [[Node: Placeholder_1 = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%expect_exception tf.errors.InvalidArgumentError\n",
    "\n",
    "sess.run(sum_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that we had to specify the `dtype` of our placeholder tensor.  That means that it's time to discuss what exactly we mean by \"tensor\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor: The data types and shapes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes, a tensor can be thought of as a generalization of a matrix.  A vector is a one-dimensional array of numbers and a matrix is a two-dimensional array.  A tensor then is an *n*-dimensional array of numbers.  Both vectors and matrices are just special cases of tensors.  (Mathematicians may quibble with this definition, insisting that tensors are defined by how they transform under coordinate transformations.  They have a point, but one that doesn't matter for the purposes of TensorFlow.)\n",
    "\n",
    "Thus, when specifying a tensor, we must give both the number of dimensions and the size of each dimension.  This is done through the `shape` data, which contains the size of each dimension.  If we look at an existing tensor, we can see that it has a shape of `[]`, indicating a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we make a $2\\times3$ matrix, for example, we see that this is reflected in its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(3)])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1,2,3],[4,5,6]]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, TensorFlow is able to work out the shape from the input values.  With placeholders, however, we generally will need to specify it.  We can give the dimensions in a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = tf.placeholder(dtype=tf.int32, shape=(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to give an appropriately shaped value in the `feed_dict`.  Note that this check happens at \"compile\" time, before any computation actually takes place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-36-d8ff53edaffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 2\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n",
      "\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n",
      "\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n",
      "\u001b[1;32m   1074\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1075\u001b[0m                              (np_val.shape, subfeed_t.name,\n",
      "\u001b[0;32m-> 1076\u001b[0;31m                               str(subfeed_t.get_shape())))\n",
      "\u001b[0m\u001b[1;32m   1077\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1078\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (2, 2) for Tensor 'Placeholder_2:0', which has shape '(2, 3)'\n"
     ]
    }
   ],
   "source": [
    "%%expect_exception ValueError\n",
    "\n",
    "sess.run(mat, {mat: [[1,2],[3,4]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we give it the right-sized input, everything works just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]], dtype=int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(mat, {mat: [[1,2,3],[4,5,6]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a dimension of `None` to indicate that a tensor can have arbitrary size along that dimension.  (Dimension mismatches here can only be caught at execution time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]], dtype=int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat2 = tf.placeholder(dtype=np.int32, shape=(2, None))\n",
    "print(sess.run(mat2, {mat2: [[1],[2]]}))\n",
    "sess.run(mat2, {mat2: [[1,2,3],[4,5,6]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `array` object returned is provided by [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sess.run(mat2, {mat2: [[1,2,3],[4,5,6]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow uses NumPy arrays to represent all (non-scalar) values.  NumPy arrays are used widely in the scientific Python community for numeric computations, as they represent a significant improvement over Python lists for these purposes.\n",
    "\n",
    "Python lists are **heterogeneous** and can be **resized**.  This makes them useful for interactive programming, as any value can be added to any list.  However, it slows computation, since we have to do a pointer lookup to access each value (and additional look-ups to find the relevant functions).\n",
    "\n",
    "In contrast, NumPy arrays are **homogeneous** and **fixed-size**.  This means that their contents can be stored contiguously in memory.  Operations can easily be broadcast to act over each element in the array.  Arrays can be of arbitrary dimensions, so they are a good fit for tensors.  NumPy arrays can be constructed out of nested lists, which we were taking advantage of previously.\n",
    "\n",
    "Because they are homogeneous, arrays (and therefore tensors) must specify which type of data they can contain.  This is indicated by an array's `dtype`.  The issue of type goes beyond simply `float` versus `int`&mdash;there are a variety of levels of precision.  As we can see above, the default integer type is 32 bits.  These types exist in both the `numpy` and `tensorflow` namespaces, where there are generally equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int32 == tf.int32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify which `dtype` to use when creating operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2.0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_int64 = tf.constant(2, dtype=np.int64)\n",
    "x_float16 = tf.constant(2, dtype=np.float16)\n",
    "sess.run([x_int64, x_float16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we can often get away with type inference, this sometimes leads to type mismatches in graphs.  It's generally good practice to specify the type, just to be safe.\n",
    "\n",
    "Here are the `dtype`s provided by NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'int': [numpy.int8, numpy.int16, numpy.int32, numpy.int64],\n",
       " 'uint': [numpy.uint8, numpy.uint16, numpy.uint32, numpy.uint64],\n",
       " 'float': [numpy.float16, numpy.float32, numpy.float64, numpy.float128],\n",
       " 'complex': [numpy.complex64, numpy.complex128, numpy.complex256],\n",
       " 'others': [bool, object, bytes, str, numpy.void]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sctypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most basic TensorFlow operations act element-wise.  This means that the shape of the output tensor is the same as that of the input tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(2), Dimension(3)]),\n",
       " TensorShape([Dimension(2), Dimension(3)]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape, (mat + mat).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware the multiplication is also element-wise by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4],\n",
       "       [ 9, 16]], dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(mat2 * mat2, {mat2: [[1,2],[3,4]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually do matrix multiplication, you can use the `tf.matmul` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7, 10],\n",
       "       [15, 22]], dtype=int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.matmul(mat2, mat2), {mat2: [[1,2],[3,4]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, Python 3's `@` operator also does matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7, 10],\n",
       "       [15, 22]], dtype=int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(mat2 @ mat2,  {mat2: [[1,2],[3,4]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, matrix multiplication may result in a differently-shaped output.\n",
    "\n",
    "TensorFlow provides a number of `reduce_*` operations.  These run the specified reduction function over the specified axis, or over all axes if none is specified.  This will sum the columns of the matrix, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9], dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.reduce_sum(mat, axis=0), {mat: [[1,2,3],[4,5,6]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Reducing tensors of arbitrary shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a graph to take in a $5\\times n$ tensor of floats and return a single float, the sum of the squares of the average value of each row.  Test it on the following inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "matph = tf.placeholder(dtype=np.float, shape=(5, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "input1 = np.random.randn(5, 2)\n",
    "# Answer: 1.6559478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.62434536, -0.61175641],\n",
       "       [-0.52817175, -1.07296862],\n",
       "       [ 0.86540763, -2.3015387 ],\n",
       "       [ 1.74481176, -0.7612069 ],\n",
       "       [ 0.3190391 , -0.24937038]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid reduction dimension 1 for input with 1 dimensions. for 'Sum_5' (op: 'Sum') with input shapes: [5], [] and with computed input tensors: input[1] = <1>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1575\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1577\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Invalid reduction dimension 1 for input with 1 dimensions. for 'Sum_5' (op: 'Sum') with input shapes: [5], [] and with computed input tensors: input[1] = <1>.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-86e3c7169d5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msqr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msumsqr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msumsqr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 instructions)\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_sum\u001b[0;34m(input_tensor, axis, keepdims, name, reduction_indices, keep_dims)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                                   reduction_indices),\n\u001b[1;32m   1306\u001b[0m                                    \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1307\u001b[0;31m                                    name=name))\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m   8257\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   8258\u001b[0m         \u001b[0;34m\"Sum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8259\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   8260\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8261\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 instructions)\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3153\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3154\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3155\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3156\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1729\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1730\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1731\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1577\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid reduction dimension 1 for input with 1 dimensions. for 'Sum_5' (op: 'Sum') with input shapes: [5], [] and with computed input tensors: input[1] = <1>."
     ]
    }
   ],
   "source": [
    "means = tf.reduce_mean(matph, axis=1)\n",
    "sqr = tf.square(means)\n",
    "sumsqr = tf.reduce_sum(sqr, axis=1)\n",
    "sess.run(sumsqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "input2 = np.random.randn(5, 200)\n",
    "# Answer: 0.035791952"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus far, we have been referring to the computation graph as some abstract concept.  It's actually a real thing.  TensorFlow provides a default graph, to which operations are added by default.  We can get a reference to it, if we'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x7fa00eed3e80>\n"
     ]
    }
   ],
   "source": [
    "g = tf.get_default_graph()\n",
    "\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a list of all the operations on the current graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'input_x' type=Const>,\n",
       " <tf.Operation 'input_y' type=Const>,\n",
       " <tf.Operation 'sum' type=Add>,\n",
       " <tf.Operation 'add' type=Add>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'Const_1' type=Const>,\n",
       " <tf.Operation 'Const_2' type=Const>,\n",
       " <tf.Operation 'Const_3' type=Const>,\n",
       " <tf.Operation 'Equal' type=Equal>,\n",
       " <tf.Operation 'multiply' type=Mul>,\n",
       " <tf.Operation 'multiply_1' type=Mul>,\n",
       " <tf.Operation 'multiply_2' type=Mul>,\n",
       " <tf.Operation 'Placeholder' type=Placeholder>,\n",
       " <tf.Operation 'Add_1' type=Add>,\n",
       " <tf.Operation 'Placeholder_1' type=Placeholder>,\n",
       " <tf.Operation 'Add_2' type=Add>,\n",
       " <tf.Operation 'Const_4' type=Const>,\n",
       " <tf.Operation 'Placeholder_2' type=Placeholder>,\n",
       " <tf.Operation 'Placeholder_3' type=Placeholder>,\n",
       " <tf.Operation 'Const_5' type=Const>,\n",
       " <tf.Operation 'Const_6' type=Const>,\n",
       " <tf.Operation 'add_3' type=Add>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'MatMul' type=MatMul>,\n",
       " <tf.Operation 'matmul_1' type=MatMul>,\n",
       " <tf.Operation 'Sum_1/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Sum_1' type=Sum>,\n",
       " <tf.Operation 'Placeholder_4' type=Placeholder>,\n",
       " <tf.Operation 'Sum_2/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Sum_2' type=Sum>,\n",
       " <tf.Operation 'Sum_3/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Sum_3' type=Sum>,\n",
       " <tf.Operation 'Mean/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Mean' type=Mean>,\n",
       " <tf.Operation 'Mean_1/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Mean_1' type=Mean>,\n",
       " <tf.Operation 'Mean_2/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Mean_2' type=Mean>,\n",
       " <tf.Operation 'mul_1' type=Mul>,\n",
       " <tf.Operation 'Mean_3/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Mean_3' type=Mean>,\n",
       " <tf.Operation 'Mean_4/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Mean_4' type=Mean>,\n",
       " <tf.Operation 'mul_2' type=Mul>,\n",
       " <tf.Operation 'Mean_5/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Mean_5' type=Mean>,\n",
       " <tf.Operation 'Mean_6/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Mean_6' type=Mean>,\n",
       " <tf.Operation 'mul_3' type=Mul>,\n",
       " <tf.Operation 'Mean_7/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Mean_7' type=Mean>,\n",
       " <tf.Operation 'Mean_8/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Mean_8' type=Mean>,\n",
       " <tf.Operation 'mul_4' type=Mul>,\n",
       " <tf.Operation 'Mean_9/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Mean_9' type=Mean>,\n",
       " <tf.Operation 'Mean_10/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Mean_10' type=Mean>,\n",
       " <tf.Operation 'Square' type=Square>,\n",
       " <tf.Operation 'Sum_5/reduction_indices' type=Const>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are all of the operations that we've created in this notebook.  We've been using the default graph for convenience, but it's better practice to use a dedicated graph for each computation.  (That said, remember that TensorFlow is smart enough to only evaluate the necessary operations to give us any particular result.)  We can instantiate a new graph like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = tf.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to add operations to a particular graph is to use the `as_default()` context handler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g2.as_default():\n",
    "    a = tf.constant(12, name=\"constant_a\")\n",
    "    b = tf.constant(16, name=\"constant_b\")\n",
    "    sum_g2 = a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see these operations got added to the new graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'constant_a' type=Const>,\n",
       " <tf.Operation 'constant_b' type=Const>,\n",
       " <tf.Operation 'add' type=Add>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an issue of best practices, you should not do as we've done here, using the default graph implicitly for some operations and a second graph explicitly for other.  If you need multiple graphs, it's best to assemble each in its own `with` block, so that there's no confusion about which graph is getting which operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already created a session to run operations previously.  The session abstracts the environment in which a graph is executed.  Each session is associated with a specific graph, so if we want to evaluate `sum_g2`, we'll have to make a session for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess2 = tf.Session(graph=g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess2.run(sum_g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple sessions can reference the same graph.  Each of them keeps track of its internal state separately, as we'll see when discussing variables in the next notebook.  If you don't specify a graph when creating a session, the default graph is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Session().graph == g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are finished with a session, remember to close it, to free the associated resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use sessions as context managers.  They close themselves on exit, so you don't have to do this explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g2) as s2:\n",
    "    print(s2.run(sum_g2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is probably the best approach if you find yourself using multiple sessions.  However, in these notebooks, we tend to have sessions that need to span multiple cells.  We have a little reset function that we'll be using instead.  It closes the current session and opens a new one, in the global variable `sess`.  It also resets the default graph.  All of our work will be in these objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_tf():\n",
    "    global sess\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Aside:** TensorFlow also provides an `InteractiveSession` designed for use in interactive environments like this one.  It allows you to use the `eval()` method on tensors to get their values in the default session.  We think \"Explicit is better than implicit,\" at least for learning, so we're using sessions explicitly.  But once you get a handle on these concepts, you might find that `InteractiveSession` speeds up your work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard) is a web-based tool to help you visualize your TensorFlow graphs and runs.  While running your graphs, you write to event files.  When you launch TensorBoard, it will run a local web server with visualizations of this material.  A `FileWriter` is used to create these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        var tb_url = Jupyter.notebook.base_url + \"proxy/6006/\";\n",
       "        element.html(\n",
       "            \"Run at the command line: <tt>tensorboard --logdir=tb/intro_graph</tt><br />\" +\n",
       "            \"Then open <a href='\" + tb_url + \"' target='_blank'>\" + tb_url + \"</a>\"\n",
       "        );\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer = tf.summary.FileWriter('./tb/intro_graph', g)\n",
    "\n",
    "tensorboard_cmd('tb/intro_graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can launch `tensorboard`.  As the instructions above say, on a terminal in this directory, run\n",
    "```bash\n",
    "tensorboard --logdir=tb/intro_graph\n",
    "```\n",
    "This will start up a web server on port 6006.  If you are running this on your own computer, you can just visit `localhost:6006`.  On the training cloud computer, you can't access this port directly.  Instead, we've set up a proxy to forward these connections.  Use the link in the output above.\n",
    "\n",
    "Visiting TensorBoard, you will see nothing on the first page.  If you click on the \"Graphs\" header, though, you'll get a visualization of the computation graph.  This allows you to zoom and scroll through the graph, examining the operations and the tensors passed between them.  Right now, you'll probably see a lot of small, disconnected sub-graphs.  That's what's constructed in this notebook, but this is an atypical use.\n",
    "\n",
    "Another useful capability of TensorBoard is to keep track of some value each time a computation is run.  (This will be useful to track the evolving loss as a model is being trained, for example.)  For example, to track `sum_` each time we run it, we can create a summary operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sum_:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.scalar('sum_', sum_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to merge all of the summaries together.  It's sort of pointless here, with a single summary, but this would allow us to generate multiple summaries in a single operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run both the summation of the summary generation step and use the `writer.add_summary` method to write the summary to the event file.  This function takes an optional second argument, a step counter.  This allows you to track how a summary value changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    summary, _ = sess.run([merged, sum_], {x: 10*i, y: -i*i})\n",
    "    writer.add_summary(summary, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good practice to close the `FileWriter` when you're done with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to stop and restart the `tensorboard` server.  Once you do, you should see *sum_* on the \"Scalars\" page, plotting how it changes over time.\n",
    "\n",
    "Be careful about re-running this code.  It will write another event file to the same directory, which can slightly confuse `tensorboard`.  One solution is to include the current time in the directory name passed to the `FileWriter`.\n",
    "\n",
    "We don't make too much use of TensorBoard in these notebooks, preferring visualizations that we've integrated into the notebook.  Don't let that dissuade you from using it in your own work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2017 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
